# Module 1: App Shell + Observability

## Complexity: ğŸ”´ Complex
Break into 4 sub-plans for manageable execution.

---

## Overview

Build the foundation: auth, chat UI with threads, OpenAI Responses API (managed RAG), and LangSmith tracing.

**Key Constraint:** Design for easy removal in Module 2 when switching to Chat Completions API.

---

## Sub-Plan Breakdown

| Sub-Plan | Name | Complexity |
|----------|------|------------|
| 1.1 | Project Scaffolding + Environment | âœ… Simple |
| 1.2 | Supabase Setup + Authentication | âš ï¸ Medium |
| 1.3 | Chat UI + State Management | âš ï¸ Medium |
| 1.4 | OpenAI + LangSmith + SSE Streaming | âš ï¸ Medium |

---

## Project Structure

```
claude-code-agentic-rag-masterclass/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ venv/                     # Python venv (gitignored)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py               # FastAPI entry point
â”‚   â”‚   â”œâ”€â”€ config.py             # Environment settings
â”‚   â”‚   â”œâ”€â”€ api/routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py           # Thread/message endpoints
â”‚   â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ openai_service.py # OpenAI Responses API (replace in M2)
â”‚   â”‚   â”‚   â””â”€â”€ supabase_service.py
â”‚   â”‚   â”œâ”€â”€ models/               # Pydantic models
â”‚   â”‚   â””â”€â”€ utils/sse.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth/             # Login, Signup, AuthGuard
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/             # ThreadList, MessageList, etc.
â”‚   â”‚   â”‚   â””â”€â”€ layout/           # Header, Sidebar
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useAuth.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useChat.ts
â”‚   â”‚   â”‚   â””â”€â”€ useSSE.ts
â”‚   â”‚   â”œâ”€â”€ contexts/AuthContext.tsx
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ supabase.ts
â”‚   â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”‚   â””â”€â”€ pages/
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ package.json
â””â”€â”€ supabase/migrations/
    â””â”€â”€ 001_initial_schema.sql
```

---

## Database Schema

```sql
-- Enable pgvector (for future modules)
CREATE EXTENSION IF NOT EXISTS vector;

-- Threads
CREATE TABLE threads (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
    openai_thread_id TEXT NOT NULL,
    title TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Messages (local cache - OpenAI is authoritative in M1)
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    thread_id UUID NOT NULL REFERENCES threads(id) ON DELETE CASCADE,
    openai_message_id TEXT,
    role TEXT NOT NULL CHECK (role IN ('user', 'assistant')),
    content TEXT NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_threads_user_id ON threads(user_id);
CREATE INDEX idx_messages_thread_id ON messages(thread_id);

-- RLS
ALTER TABLE threads ENABLE ROW LEVEL SECURITY;
ALTER TABLE messages ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can CRUD own threads" ON threads
    FOR ALL USING (auth.uid() = user_id);

CREATE POLICY "Users can CRUD messages in own threads" ON messages
    FOR ALL USING (EXISTS (
        SELECT 1 FROM threads WHERE threads.id = messages.thread_id
        AND threads.user_id = auth.uid()
    ));
```

---

## API Endpoints

```
POST   /api/threads              # Create thread
GET    /api/threads              # List user's threads
GET    /api/threads/{id}         # Get thread + messages
DELETE /api/threads/{id}         # Delete thread
POST   /api/threads/{id}/messages # Send message (SSE stream response)
```

---

## Environment Variables

**Backend:**
```
SUPABASE_URL=
SUPABASE_SERVICE_KEY=
SUPABASE_JWT_SECRET=
OPENAI_API_KEY=
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=rag-masterclass
```

**Frontend:**
```
VITE_SUPABASE_URL=
VITE_SUPABASE_ANON_KEY=
VITE_API_URL=http://localhost:8000
```

---

## Sub-Plan 1.1: Project Scaffolding

### Tasks
1. Create `backend/` with venv, FastAPI, requirements.txt
2. Create `frontend/` with Vite + React + TypeScript
3. Configure Tailwind + shadcn/ui
4. Create .env.example files
5. Update .gitignore

### Validation
- `uvicorn app.main:app --reload` starts on :8000
- `npm run dev` starts on :5173
- Health endpoint returns OK

---

## Sub-Plan 1.2: Supabase + Auth

### Prerequisites
- Create Supabase project manually
- Get project URL and keys

### Tasks
1. Run database migration (schema + RLS)
2. Create frontend Supabase client
3. Create AuthContext with session management
4. Build Login/Signup pages with shadcn/ui
5. Create backend JWT verification middleware

### Validation
- Sign up creates user in Supabase
- Login persists session
- Protected routes redirect to login
- Backend rejects requests without valid JWT

---

## Sub-Plan 1.3: Chat UI

### Tasks
1. Build Header + Sidebar layout
2. Build ThreadList component
3. Build MessageList + MessageInput
4. Build StreamingMessage for partial responses
5. Create useChat hook for state management
6. Create Chat page composing all components

### Validation
- Can create/select/delete threads
- Messages display correctly (user vs assistant styling)
- Auto-scroll to bottom on new messages
- Empty states handled

---

## Sub-Plan 1.4: OpenAI + LangSmith + SSE

### Tasks
1. Configure LangSmith (env vars, wrap OpenAI client)
2. Create openai_service.py with:
   - `create_thread()`
   - `send_message_stream()` async generator
3. Create chat API routes with SSE responses
4. Create useSSE hook for frontend
5. Wire up streaming in useChat
6. End-to-end integration test

### Key Pattern: LangSmith Wrapping
```python
from openai import OpenAI
from langsmith.wrappers import wrap_openai
from langsmith import traceable

client = wrap_openai(OpenAI())

@traceable(name="send_message")
async def send_message_stream(thread_id: str, content: str):
    # OpenAI Responses API call with streaming
    ...
```

### Validation
- Message sends and response streams back
- LangSmith dashboard shows traces
- Messages persist on refresh
- RLS enforced (users only see own threads)

---

## Verification Checklist

- [ ] Sign up / login / logout works
- [ ] Can create and switch between threads
- [ ] Messages stream in real-time
- [ ] Messages persist across refresh
- [ ] LangSmith shows traces for all LLM calls
- [ ] RLS prevents cross-user data access
- [ ] Both frontend and backend start without errors

---

## Files to Create (in order)

1. `backend/requirements.txt`
2. `backend/app/config.py`
3. `backend/app/main.py`
4. `frontend/` (via Vite scaffold)
5. `supabase/migrations/001_initial_schema.sql`
6. `frontend/src/lib/supabase.ts`
7. `frontend/src/contexts/AuthContext.tsx`
8. `frontend/src/pages/Login.tsx`, `Signup.tsx`
9. `backend/app/api/middleware/auth.py`
10. `frontend/src/components/chat/*`
11. `frontend/src/hooks/useChat.ts`
12. `backend/app/services/openai_service.py`
13. `backend/app/api/routes/chat.py`
14. `frontend/src/hooks/useSSE.ts`
